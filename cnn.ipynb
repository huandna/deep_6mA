{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.931</td>\n",
       "      <td>4.497</td>\n",
       "      <td>18.630</td>\n",
       "      <td>39.022</td>\n",
       "      <td>85.833</td>\n",
       "      <td>206.750</td>\n",
       "      <td>3.497</td>\n",
       "      <td>4.688</td>\n",
       "      <td>8.248</td>\n",
       "      <td>19.295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.098</td>\n",
       "      <td>6.869</td>\n",
       "      <td>28.129</td>\n",
       "      <td>59.694</td>\n",
       "      <td>154.333</td>\n",
       "      <td>255.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.923</td>\n",
       "      <td>7.568</td>\n",
       "      <td>11.007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774</td>\n",
       "      <td>2.949</td>\n",
       "      <td>13.966</td>\n",
       "      <td>30.463</td>\n",
       "      <td>73.667</td>\n",
       "      <td>122.000</td>\n",
       "      <td>2.640</td>\n",
       "      <td>3.697</td>\n",
       "      <td>5.344</td>\n",
       "      <td>6.432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.747</td>\n",
       "      <td>1.906</td>\n",
       "      <td>9.567</td>\n",
       "      <td>22.019</td>\n",
       "      <td>42.222</td>\n",
       "      <td>69.286</td>\n",
       "      <td>1.692</td>\n",
       "      <td>2.744</td>\n",
       "      <td>4.653</td>\n",
       "      <td>6.483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766</td>\n",
       "      <td>4.530</td>\n",
       "      <td>16.569</td>\n",
       "      <td>34.357</td>\n",
       "      <td>70.733</td>\n",
       "      <td>173.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.027</td>\n",
       "      <td>4.261</td>\n",
       "      <td>6.388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56720</th>\n",
       "      <td>1.429</td>\n",
       "      <td>4.559</td>\n",
       "      <td>18.663</td>\n",
       "      <td>38.568</td>\n",
       "      <td>68.267</td>\n",
       "      <td>137.500</td>\n",
       "      <td>3.423</td>\n",
       "      <td>4.909</td>\n",
       "      <td>6.136</td>\n",
       "      <td>10.835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56721</th>\n",
       "      <td>4.459</td>\n",
       "      <td>3.322</td>\n",
       "      <td>15.742</td>\n",
       "      <td>37.891</td>\n",
       "      <td>82.333</td>\n",
       "      <td>156.250</td>\n",
       "      <td>2.754</td>\n",
       "      <td>4.636</td>\n",
       "      <td>8.117</td>\n",
       "      <td>16.218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56722</th>\n",
       "      <td>3.903</td>\n",
       "      <td>6.506</td>\n",
       "      <td>29.167</td>\n",
       "      <td>69.526</td>\n",
       "      <td>121.600</td>\n",
       "      <td>218.500</td>\n",
       "      <td>5.310</td>\n",
       "      <td>7.868</td>\n",
       "      <td>10.772</td>\n",
       "      <td>12.101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56723</th>\n",
       "      <td>1.381</td>\n",
       "      <td>3.616</td>\n",
       "      <td>14.907</td>\n",
       "      <td>30.338</td>\n",
       "      <td>63.750</td>\n",
       "      <td>142.500</td>\n",
       "      <td>2.899</td>\n",
       "      <td>3.425</td>\n",
       "      <td>6.333</td>\n",
       "      <td>7.500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56724</th>\n",
       "      <td>3.740</td>\n",
       "      <td>4.312</td>\n",
       "      <td>17.121</td>\n",
       "      <td>35.800</td>\n",
       "      <td>72.056</td>\n",
       "      <td>138.750</td>\n",
       "      <td>3.019</td>\n",
       "      <td>4.314</td>\n",
       "      <td>7.718</td>\n",
       "      <td>12.281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56725 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2       3        4        5      6      7       8    \\\n",
       "0      0.931  4.497  18.630  39.022   85.833  206.750  3.497  4.688   8.248   \n",
       "1      1.098  6.869  28.129  59.694  154.333  255.000  0.000  4.923   7.568   \n",
       "2      0.774  2.949  13.966  30.463   73.667  122.000  2.640  3.697   5.344   \n",
       "3      0.747  1.906   9.567  22.019   42.222   69.286  1.692  2.744   4.653   \n",
       "4      0.766  4.530  16.569  34.357   70.733  173.000  0.000  3.027   4.261   \n",
       "...      ...    ...     ...     ...      ...      ...    ...    ...     ...   \n",
       "56720  1.429  4.559  18.663  38.568   68.267  137.500  3.423  4.909   6.136   \n",
       "56721  4.459  3.322  15.742  37.891   82.333  156.250  2.754  4.636   8.117   \n",
       "56722  3.903  6.506  29.167  69.526  121.600  218.500  5.310  7.868  10.772   \n",
       "56723  1.381  3.616  14.907  30.338   63.750  142.500  2.899  3.425   6.333   \n",
       "56724  3.740  4.312  17.121  35.800   72.056  138.750  3.019  4.314   7.718   \n",
       "\n",
       "          9    ...  96   97   98   99   100  101  102  103  104  105  \n",
       "0      19.295  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0  \n",
       "1      11.007  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0    0  \n",
       "2       6.432  ...  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0    0  \n",
       "3       6.483  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0    0  \n",
       "4       6.388  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0    0  \n",
       "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "56720  10.835  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1  \n",
       "56721  16.218  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0    1  \n",
       "56722  12.101  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0    1  \n",
       "56723   7.500  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    1  \n",
       "56724  12.281  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0    1  \n",
       "\n",
       "[56725 rows x 106 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "import  pandas as  pd\n",
    "df= pd.read_csv(\"./20210331_train.data\",names=[i for i in range(106)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.984,  2.965, 14.33 , ...,  0.   ,  0.   ,  0.   ],\n",
       "       [ 1.222,  5.983, 23.114, ...,  0.   ,  0.   ,  0.   ],\n",
       "       [ 5.727,  6.336, 28.056, ...,  0.   ,  0.   ,  1.   ],\n",
       "       ...,\n",
       "       [ 0.785,  5.592, 21.398, ...,  0.   ,  1.   ,  0.   ],\n",
       "       [ 1.358,  4.711, 16.469, ...,  0.   ,  0.   ,  1.   ],\n",
       "       [ 0.645,  5.   , 17.775, ...,  0.   ,  1.   ,  0.   ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#随机打乱数据\n",
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "data = df.values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1维CNN多频道数据处理\n",
    "# result=[]\n",
    "# time_steps = 4 \n",
    "# for i in range(len(data)-time_steps):\n",
    "#     result.append(data[i:i+time_steps].T)\n",
    "# result=np.array(result)\n",
    "#训练集和测试集的数据量划分\n",
    "# train_size = int(0.8*len(result))\n",
    "# print(train_size)\n",
    "# #训练集切分\n",
    "# train = result[:train_size,:]\n",
    "# x_train = train[:,:-1]\n",
    "# y_train = train[:,-1][:,-1]\n",
    "# x_test = result[train_size:,:-1]\n",
    "# y_test = result[train_size:,-1][:,-1]\n",
    "# print(\"X_train\", x_train.shape)\n",
    "# print(\"y_train\", y_train.shape)\n",
    "# print(\"X_test\", x_test.shape)\n",
    "# print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45380\n",
      "X_train (45380, 105)\n",
      "y_train (45380,)\n",
      "X_test (11345, 105)\n",
      "y_test (11345,)\n"
     ]
    }
   ],
   "source": [
    "# 这里是一个频道\n",
    "result=data\n",
    "data.shape\n",
    "train_size = int(0.8*len(result))\n",
    "print(train_size)\n",
    "#训练集切分\n",
    "train = result[:train_size]\n",
    "x_train = train[:,:-1]\n",
    "y_train = train[:,-1]\n",
    "x_test = result[train_size:,:-1]\n",
    "y_test = result[train_size:,-1]\n",
    "print(\"X_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21315"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看正负数据比例\n",
    "list(y_train).count(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.896],\n",
       "        [ 3.859],\n",
       "        [15.504],\n",
       "        ...,\n",
       "        [ 1.   ],\n",
       "        [ 0.   ],\n",
       "        [ 0.   ]],\n",
       "\n",
       "       [[ 0.822],\n",
       "        [ 4.117],\n",
       "        [17.441],\n",
       "        ...,\n",
       "        [ 0.   ],\n",
       "        [ 1.   ],\n",
       "        [ 0.   ]],\n",
       "\n",
       "       [[ 5.5  ],\n",
       "        [ 6.982],\n",
       "        [31.938],\n",
       "        ...,\n",
       "        [ 0.   ],\n",
       "        [ 1.   ],\n",
       "        [ 0.   ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.785],\n",
       "        [ 5.592],\n",
       "        [21.398],\n",
       "        ...,\n",
       "        [ 0.   ],\n",
       "        [ 0.   ],\n",
       "        [ 1.   ]],\n",
       "\n",
       "       [[ 1.358],\n",
       "        [ 4.711],\n",
       "        [16.469],\n",
       "        ...,\n",
       "        [ 0.   ],\n",
       "        [ 0.   ],\n",
       "        [ 0.   ]],\n",
       "\n",
       "       [[ 0.645],\n",
       "        [ 5.   ],\n",
       "        [17.775],\n",
       "        ...,\n",
       "        [ 0.   ],\n",
       "        [ 0.   ],\n",
       "        [ 1.   ]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据重塑\n",
    "# cnn1D接收的数据\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 102, 80)           400       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 99, 80)            25680     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 99, 80)            320       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 99, 80)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 49, 80)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3920)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                39210     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 65,621\n",
      "Trainable params: 65,461\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#模型构建\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv1D(80, kernel_size=4, activation='relu',input_shape = (105, 1)))\n",
    "model.add(Conv1D(80, kernel_size=4, activation='relu',input_shape = (105, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))#dropoutlayer with a dropout rate of 0.5\n",
    "model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid'))#A maximum pooling layer with a pool size of 2 was used\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu', use_bias=True))#followed by a fully connected layer comprising 10 neurons with the use of the ReLU activation\n",
    "model.add(Dense(1, activation='sigmoid', use_bias=True))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型编译\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36304 samples, validate on 9076 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.4570 - accuracy: 0.7698 - val_loss: 0.4014 - val_accuracy: 0.8580\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.2490 - accuracy: 0.8978 - val_loss: 0.2247 - val_accuracy: 0.9054\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.2144 - accuracy: 0.9133 - val_loss: 0.1935 - val_accuracy: 0.9296\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.2003 - accuracy: 0.9198 - val_loss: 0.1919 - val_accuracy: 0.9225\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.1942 - accuracy: 0.9225 - val_loss: 0.1853 - val_accuracy: 0.9306\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.1872 - accuracy: 0.9251 - val_loss: 0.1846 - val_accuracy: 0.9281\n",
      "Epoch 7/100\n",
      " - 8s - loss: 0.1827 - accuracy: 0.9271 - val_loss: 0.2106 - val_accuracy: 0.9251\n",
      "Epoch 8/100\n",
      " - 8s - loss: 0.1797 - accuracy: 0.9272 - val_loss: 0.1830 - val_accuracy: 0.9322\n",
      "Epoch 9/100\n",
      " - 8s - loss: 0.1763 - accuracy: 0.9312 - val_loss: 0.1899 - val_accuracy: 0.9281\n",
      "Epoch 10/100\n",
      " - 8s - loss: 0.1725 - accuracy: 0.9316 - val_loss: 0.2011 - val_accuracy: 0.9275\n",
      "Epoch 11/100\n",
      " - 8s - loss: 0.1654 - accuracy: 0.9341 - val_loss: 0.2498 - val_accuracy: 0.9065\n",
      "Epoch 12/100\n",
      " - 8s - loss: 0.1649 - accuracy: 0.9348 - val_loss: 0.3743 - val_accuracy: 0.8549\n",
      "Epoch 13/100\n",
      " - 8s - loss: 0.1604 - accuracy: 0.9368 - val_loss: 0.2080 - val_accuracy: 0.9301\n",
      "Epoch 14/100\n",
      " - 8s - loss: 0.1583 - accuracy: 0.9368 - val_loss: 0.1995 - val_accuracy: 0.9293\n",
      "Epoch 15/100\n",
      " - 8s - loss: 0.1515 - accuracy: 0.9400 - val_loss: 0.2725 - val_accuracy: 0.9028\n",
      "Epoch 16/100\n",
      " - 8s - loss: 0.1443 - accuracy: 0.9429 - val_loss: 0.1708 - val_accuracy: 0.9408\n",
      "Epoch 17/100\n",
      " - 8s - loss: 0.1392 - accuracy: 0.9445 - val_loss: 0.1272 - val_accuracy: 0.9538\n",
      "Epoch 18/100\n",
      " - 8s - loss: 0.1360 - accuracy: 0.9459 - val_loss: 0.1848 - val_accuracy: 0.9401\n",
      "Epoch 19/100\n",
      " - 8s - loss: 0.1270 - accuracy: 0.9508 - val_loss: 0.4145 - val_accuracy: 0.8243\n",
      "Epoch 20/100\n",
      " - 8s - loss: 0.1198 - accuracy: 0.9547 - val_loss: 0.1407 - val_accuracy: 0.9470\n",
      "Epoch 21/100\n",
      " - 8s - loss: 0.1015 - accuracy: 0.9610 - val_loss: 0.1161 - val_accuracy: 0.9645\n",
      "Epoch 22/100\n",
      " - 8s - loss: 0.0964 - accuracy: 0.9640 - val_loss: 0.1557 - val_accuracy: 0.9494\n",
      "Epoch 23/100\n",
      " - 8s - loss: 0.0879 - accuracy: 0.9682 - val_loss: 0.1239 - val_accuracy: 0.9633\n",
      "Epoch 24/100\n",
      " - 8s - loss: 0.0794 - accuracy: 0.9704 - val_loss: 0.0973 - val_accuracy: 0.9708\n",
      "Epoch 25/100\n",
      " - 8s - loss: 0.0768 - accuracy: 0.9713 - val_loss: 0.2106 - val_accuracy: 0.9326\n",
      "Epoch 26/100\n",
      " - 8s - loss: 0.0712 - accuracy: 0.9743 - val_loss: 0.0764 - val_accuracy: 0.9780\n",
      "Epoch 27/100\n",
      " - 8s - loss: 0.0687 - accuracy: 0.9750 - val_loss: 0.1311 - val_accuracy: 0.9618\n",
      "Epoch 28/100\n",
      " - 8s - loss: 0.0625 - accuracy: 0.9762 - val_loss: 0.1166 - val_accuracy: 0.9679\n",
      "Epoch 29/100\n",
      " - 8s - loss: 0.0623 - accuracy: 0.9769 - val_loss: 0.1763 - val_accuracy: 0.9614\n",
      "Epoch 30/100\n",
      " - 8s - loss: 0.0598 - accuracy: 0.9788 - val_loss: 0.2554 - val_accuracy: 0.8954\n",
      "Epoch 31/100\n",
      " - 8s - loss: 0.0557 - accuracy: 0.9793 - val_loss: 0.0919 - val_accuracy: 0.9739\n",
      "Epoch 32/100\n",
      " - 8s - loss: 0.0524 - accuracy: 0.9815 - val_loss: 0.0901 - val_accuracy: 0.9779\n",
      "Epoch 33/100\n",
      " - 8s - loss: 0.0520 - accuracy: 0.9821 - val_loss: 0.1041 - val_accuracy: 0.9744\n",
      "Epoch 34/100\n",
      " - 8s - loss: 0.0509 - accuracy: 0.9817 - val_loss: 0.1764 - val_accuracy: 0.9643\n",
      "Epoch 35/100\n",
      " - 8s - loss: 0.0489 - accuracy: 0.9826 - val_loss: 0.0564 - val_accuracy: 0.9824\n",
      "Epoch 36/100\n",
      " - 8s - loss: 0.0483 - accuracy: 0.9837 - val_loss: 0.1820 - val_accuracy: 0.9705\n",
      "Epoch 37/100\n",
      " - 8s - loss: 0.0461 - accuracy: 0.9838 - val_loss: 0.1056 - val_accuracy: 0.9803\n",
      "Epoch 38/100\n",
      " - 8s - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.0715 - val_accuracy: 0.9866\n",
      "Epoch 39/100\n",
      " - 8s - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.2240 - val_accuracy: 0.9581\n",
      "Epoch 40/100\n",
      " - 8s - loss: 0.0460 - accuracy: 0.9845 - val_loss: 0.0518 - val_accuracy: 0.9862\n",
      "Epoch 41/100\n",
      " - 8s - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.1521 - val_accuracy: 0.9622\n",
      "Epoch 42/100\n",
      " - 8s - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.2170 - val_accuracy: 0.9536\n",
      "Epoch 43/100\n",
      " - 8s - loss: 0.0433 - accuracy: 0.9849 - val_loss: 0.0880 - val_accuracy: 0.9742\n",
      "Epoch 44/100\n",
      " - 8s - loss: 0.0450 - accuracy: 0.9849 - val_loss: 0.0569 - val_accuracy: 0.9879\n",
      "Epoch 45/100\n",
      " - 8s - loss: 0.0454 - accuracy: 0.9852 - val_loss: 0.0600 - val_accuracy: 0.9864\n",
      "Epoch 46/100\n",
      " - 8s - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.0611 - val_accuracy: 0.9882\n",
      "Epoch 47/100\n",
      " - 8s - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.0534 - val_accuracy: 0.9839\n",
      "Epoch 48/100\n",
      " - 8s - loss: 0.0435 - accuracy: 0.9855 - val_loss: 0.0493 - val_accuracy: 0.9880\n",
      "Epoch 49/100\n",
      " - 8s - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.1142 - val_accuracy: 0.9781\n",
      "Epoch 50/100\n",
      " - 8s - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0929 - val_accuracy: 0.9753\n",
      "Epoch 51/100\n",
      " - 8s - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.0682 - val_accuracy: 0.9862\n",
      "Epoch 52/100\n",
      " - 8s - loss: 0.0438 - accuracy: 0.9858 - val_loss: 0.0857 - val_accuracy: 0.9725\n",
      "Epoch 53/100\n",
      " - 8s - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.0470 - val_accuracy: 0.9880\n",
      "Epoch 54/100\n",
      " - 8s - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0540 - val_accuracy: 0.9887\n",
      "Epoch 55/100\n",
      " - 8s - loss: 0.0413 - accuracy: 0.9863 - val_loss: 0.0641 - val_accuracy: 0.9872\n",
      "Epoch 56/100\n",
      " - 8s - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.0417 - val_accuracy: 0.9912\n",
      "Epoch 57/100\n",
      " - 8s - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.1300 - val_accuracy: 0.9602\n",
      "Epoch 58/100\n",
      " - 8s - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.0961 - val_accuracy: 0.9783\n",
      "Epoch 59/100\n",
      " - 8s - loss: 0.0392 - accuracy: 0.9866 - val_loss: 0.0746 - val_accuracy: 0.9851\n",
      "Epoch 60/100\n",
      " - 8s - loss: 0.0421 - accuracy: 0.9866 - val_loss: 0.1053 - val_accuracy: 0.9645\n",
      "Epoch 61/100\n",
      " - 8s - loss: 0.0381 - accuracy: 0.9865 - val_loss: 0.0535 - val_accuracy: 0.9892\n",
      "Epoch 62/100\n",
      " - 8s - loss: 0.0389 - accuracy: 0.9873 - val_loss: 0.0498 - val_accuracy: 0.9869\n",
      "Epoch 63/100\n",
      " - 8s - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0972 - val_accuracy: 0.9597\n",
      "Epoch 64/100\n",
      " - 8s - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0443 - val_accuracy: 0.9900\n",
      "Epoch 65/100\n",
      " - 8s - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
      "Epoch 66/100\n",
      " - 8s - loss: 0.0403 - accuracy: 0.9865 - val_loss: 0.0727 - val_accuracy: 0.9815\n",
      "Epoch 67/100\n",
      " - 8s - loss: 0.0400 - accuracy: 0.9868 - val_loss: 0.0666 - val_accuracy: 0.9859\n",
      "Epoch 68/100\n"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "history = model.fit(x_train,y_train,batch_size=128,epochs=100,validation_split=0.2,verbose=2)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估\n",
    "score = model.evaluate(x_test, y_test, batch_size=20)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from keras.models import load_model\n",
    "model.save(\"have_iparatio.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
